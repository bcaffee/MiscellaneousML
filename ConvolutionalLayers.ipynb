{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mskd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as skd\n",
    "\n",
    "china_image = skd.load_sample_image(\"china.jpg\")\n",
    "plt.imshow(china_image)\n",
    "plt.show()\n",
    "\n",
    "print(china_image.shape)\n",
    "\n",
    "#(427, 640, 3) --> height, width, # of color channels\n",
    "\n",
    "input_layer = tf.placeholder(dtype =tf.float32, shape = [None, 427, 640, 3])\n",
    "conv_1 = tf.layers.conv2d(input_layer, filters=64, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)\n",
    "print(conv_1.shape)\n",
    "\n",
    "# (None/? means that the placeholder is expecting something)\n",
    "\n",
    "#Filters - changing the color pallet but find patterns instead of just changing color\n",
    "#64 filters for the above convolutional network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427, 640, 64)\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        output = sess.run(conv_1, feed_dict = {input_layer:[china_image]})\n",
    "\n",
    "print(output[0].shape)\n",
    "\n",
    "#plt.imshow(output[0]); this won't work because the computer can't print an image with 64 color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "image_height = 28\n",
    "image_width = 28\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    \n",
    "    def __init__(self, image_height, image_width, channels, num_classes): \n",
    "        self.input_layer = tf.placeholder(dtype = tf.float32, shape = [None, image_height, image_width, channels])\n",
    "        conv_layer_1 = tf.layers.conv2d(self.input_layer, filters = 32, kernel_size = [2, 2], activation = tf.nn.relu)\n",
    "        pooling_layer_1 = tf.layers.max_pooling2d(conv_layer_1, pool_size=[2,2], strides=2)\n",
    "    \n",
    "        #Number of image numbers\n",
    "        num_classes = 10\n",
    "\n",
    "        #Second convolutional and pooling layer to speed up the process by clearing more pixels\n",
    "        conv_layer_2 = tf.layers.conv2d(self.input_layer, filters = 32, kernel_size = [2, 2], activation = tf.nn.relu)\n",
    "        pooling_layer_2 = tf.layers.max_pooling2d(conv_layer_1, pool_size=[2,2], strides=2)\n",
    "        \n",
    "        flattened_pooling = tf.layers.flatten(pooling_layer_2)\n",
    "        dense_layer = tf.layers.dense(flattened_pooling, 1024, activation = tf.nn.relu)\n",
    "        dropout = tf.layers.dropout(dense_layer, rate = 0.4, training = True)\n",
    "        outputs = tf.layers.dense(dropout, num_classes)\n",
    "        \n",
    "        self.choice = tf.argmax(outputs, axis=1) #because the output is only 1 dimensional there's only 1 axis/vector\n",
    "        self.probability = tf.nn.softmax(outputs)\n",
    "        self.labels = tf.placeholder(dtype = tf.float32, name = \"labels\")\n",
    "        \n",
    "        #short hand for the function returning two things\n",
    "        self.accuracy, self.accuracy_op = tf.metrics.accuracy(self.labels, self.choice) \n",
    "        one_hot_labels = tf.one_hot(indices=tf.cast(self.labels, dtype=tf.int32),depth=num_classes)\n",
    "        self.loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits=outputs)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "        self.train_operation = optimizer.minimize(self.loss, global_step = tf.train.get_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 08:48:34.928548 140651881477952 deprecation.py:323] From <ipython-input-4-613d6153ecba>:6: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "W0627 08:48:35.010866 140651881477952 deprecation.py:323] From <ipython-input-4-613d6153ecba>:15: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0627 08:48:35.131935 140651881477952 deprecation.py:323] From <ipython-input-4-613d6153ecba>:16: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0627 08:48:35.326409 140651881477952 deprecation.py:323] From <ipython-input-4-613d6153ecba>:17: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0627 08:48:35.409544 140651881477952 deprecation.py:323] From /home/idstudent/.local/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09375\n",
      "0.15625\n",
      "0.13541667\n",
      "0.1484375\n",
      "0.15\n",
      "0.140625\n",
      "0.125\n",
      "0.125\n",
      "0.13541667\n",
      "0.13125\n",
      "0.12215909\n",
      "0.13020833\n",
      "0.1298077\n",
      "0.12946428\n",
      "0.125\n",
      "0.12695312\n",
      "0.125\n",
      "0.125\n",
      "0.121710524\n",
      "0.1234375\n",
      "0.12648809\n",
      "0.12357955\n",
      "0.1263587\n",
      "0.123697914\n",
      "0.12375\n",
      "0.12740384\n",
      "0.13078703\n",
      "0.13058035\n",
      "0.12823276\n",
      "0.13229166\n",
      "0.13407259\n",
      "0.13378906\n",
      "0.13068181\n",
      "0.13143383\n",
      "0.13303572\n",
      "0.1310764\n",
      "0.13260135\n",
      "0.13651316\n",
      "0.13701923\n",
      "0.1375\n",
      "0.13719513\n",
      "0.1376488\n",
      "0.13880815\n",
      "0.13849431\n",
      "0.1375\n",
      "0.13722827\n",
      "0.13630319\n",
      "0.13411458\n",
      "0.13520408\n",
      "0.1325\n",
      "0.13480392\n",
      "0.13461539\n",
      "0.13443395\n",
      "0.13599537\n",
      "0.1375\n",
      "0.13839285\n",
      "0.14144737\n",
      "0.14224137\n",
      "0.14300847\n",
      "0.1453125\n",
      "0.1460041\n",
      "0.14616935\n",
      "0.14732143\n",
      "0.14746094\n",
      "0.14759615\n",
      "0.14867425\n",
      "0.14972015\n",
      "0.14981617\n",
      "0.15081522\n",
      "0.15267856\n",
      "0.15360916\n",
      "0.15581597\n",
      "0.15625\n",
      "0.1570946\n",
      "0.15708333\n",
      "0.15830593\n",
      "0.15827923\n",
      "0.15945514\n",
      "0.15783228\n",
      "0.159375\n",
      "0.16010803\n",
      "0.16158536\n",
      "0.16076808\n",
      "0.16034226\n",
      "0.16102941\n",
      "0.16388081\n",
      "0.16343391\n",
      "0.16477273\n",
      "0.16432585\n",
      "0.16458334\n",
      "0.16517857\n",
      "0.16610055\n",
      "0.1670027\n",
      "0.16888298\n",
      "0.17072369\n",
      "0.17317708\n",
      "0.17364691\n",
      "0.17506377\n",
      "0.17518939\n",
      "0.175625\n",
      "0.17636138\n",
      "0.17677696\n",
      "0.17779127\n",
      "0.17698318\n",
      "0.17738095\n",
      "0.17836085\n",
      "0.17932244\n",
      "0.1791088\n",
      "0.17918578\n",
      "0.18068182\n",
      "0.18102477\n",
      "0.18164062\n",
      "0.18252212\n",
      "0.18283992\n",
      "0.1839674\n",
      "0.18480603\n",
      "0.18643162\n",
      "0.1875\n",
      "0.1880252\n",
      "0.18932292\n",
      "0.18982439\n",
      "0.19134222\n",
      "0.19308943\n",
      "0.19430444\n",
      "0.19575\n",
      "0.19642857\n",
      "0.19783464\n",
      "0.19970703\n",
      "0.2005814\n",
      "0.2014423\n",
      "0.20229007\n",
      "0.20454545\n",
      "0.20465225\n",
      "0.2056903\n",
      "0.20694445\n",
      "0.2074908\n",
      "0.2084854\n",
      "0.20878623\n",
      "0.20885791\n",
      "0.20915179\n",
      "0.21032801\n",
      "0.21082747\n",
      "0.21263112\n",
      "0.21310765\n",
      "0.21443966\n",
      "0.21425514\n",
      "0.21471089\n",
      "0.21684965\n",
      "0.21791108\n",
      "0.21895833\n",
      "0.21999173\n",
      "0.21977796\n",
      "0.21997549\n",
      "0.2205763\n",
      "0.22137097\n",
      "0.2217548\n",
      "0.22332802\n",
      "0.22409019\n",
      "0.22464623\n",
      "0.225\n",
      "0.22612578\n",
      "0.22608025\n",
      "0.22680214\n",
      "0.22808689\n",
      "0.22935607\n",
      "0.23004518\n",
      "0.23053892\n",
      "0.2313988\n",
      "0.23132396\n",
      "0.23161764\n",
      "0.23227338\n",
      "0.2331032\n",
      "0.23410405\n",
      "0.23509338\n",
      "0.23642857\n",
      "0.23810369\n",
      "0.23923023\n",
      "0.23964186\n",
      "0.24039805\n",
      "0.24114583\n",
      "0.24154006\n",
      "0.24261676\n",
      "0.24419399\n",
      "0.24473505\n",
      "0.2456081\n",
      "0.24663979\n",
      "0.24699198\n",
      "0.24800532\n",
      "0.24818122\n",
      "0.24917763\n",
      "0.25032723\n",
      "0.25146484\n",
      "0.2525907\n",
      "0.25306058\n",
      "0.2536859\n",
      "0.2536671\n",
      "0.2536485\n",
      "0.2550505\n",
      "0.2558103\n",
      "0.256875\n",
      "0.2573072\n",
      "0.25773516\n",
      "0.25815886\n",
      "0.25888482\n",
      "0.25990853\n",
      "0.2616808\n",
      "0.26283213\n",
      "0.26367188\n",
      "0.26420453\n",
      "0.26488096\n",
      "0.26569906\n",
      "0.2662146\n",
      "0.26657864\n",
      "0.26693925\n",
      "0.26729652\n",
      "0.26880786\n",
      "0.26944125\n",
      "0.27078554\n",
      "0.2718322\n",
      "0.2725852\n",
      "0.27361426\n",
      "0.27449325\n",
      "0.27578476\n",
      "0.27734375\n",
      "0.27805555\n",
      "0.27889934\n",
      "0.27890968\n",
      "0.27891997\n",
      "0.27974892\n",
      "0.2808424\n",
      "0.2805736\n",
      "0.2811153\n",
      "0.28232297\n",
      "0.28285256\n",
      "0.28337765\n",
      "0.28456038\n",
      "0.28481013\n",
      "0.28518906\n",
      "0.2854341\n",
      "0.2860677\n",
      "0.28721473\n",
      "0.2877066\n",
      "0.28858024\n",
      "0.2885502\n",
      "0.28915817\n",
      "0.29001525\n",
      "0.29061234\n",
      "0.29133064\n",
      "0.29216868\n",
      "0.29275\n",
      "0.2932022\n",
      "0.2937748\n",
      "0.29483697\n",
      "0.29429135\n",
      "0.29534313\n",
      "0.2965088\n",
      "0.2966926\n",
      "0.29723838\n",
      "0.2981419\n",
      "0.2986779\n",
      "0.29909003\n",
      "0.2997376\n",
      "0.29978612\n",
      "0.30030775\n",
      "0.30106133\n",
      "0.30122182\n",
      "0.30184925\n",
      "0.3023554\n",
      "0.30309016\n",
      "0.3037037\n",
      "0.3040821\n",
      "0.30491728\n",
      "0.30494505\n",
      "0.30565694\n",
      "0.3055682\n",
      "0.30627266\n",
      "0.30640793\n",
      "0.3068795\n",
      "0.30723566\n",
      "0.3078125\n",
      "0.30871886\n",
      "0.30939716\n",
      "0.31040195\n",
      "0.31172976\n",
      "0.3125\n",
      "0.31359264\n",
      "0.3146777\n",
      "0.31532118\n",
      "0.3159602\n",
      "0.31659484\n",
      "0.31754726\n",
      "0.31849316\n",
      "0.31911263\n",
      "0.31898385\n",
      "0.31959745\n",
      "0.32084036\n",
      "0.32123315\n",
      "0.32151845\n",
      "0.32201087\n",
      "0.32260418\n",
      "0.32340115\n",
      "0.3240894\n",
      "0.32456684\n",
      "0.3255551\n",
      "0.32663935\n",
      "0.32710376\n",
      "0.3280741\n",
      "0.32873377\n",
      "0.32938915\n",
      "0.33074597\n",
      "0.33149117\n",
      "0.33183092\n",
      "0.33216852\n",
      "\n",
      "It is done.\n",
      "\n",
      "[3]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADftJREFUeJzt3X+MXXWZx/HP0zJtsVRo01K7pVKK7UJhQ9FJFdFdCIuLxFhMFtZm1x2M7rhZ2dWkiZJmEzGKIUZAN2vcVGksCT9k+VkjKrVqAHdSOmVZWqnaLjuLtZMOTUdbdLftTB//mFMytnO+9/be8+NOn/crae695zn3nCcXPnPuvd9zz9fcXQDimVJ3AwDqQfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwR1RpU7m2bTfYZmVrlLIJT/1291xA9bM+u2FX4zu07SVyRNlfQNd78jtf4MzdTb7Zp2dgkgYYtvbnrdlt/2m9lUSV+V9F5JyyWtNrPlrW4PQLXa+cy/UtJud3/Z3Y9IelDSqmLaAlC2dsK/UNIvxz3eky37A2bWa2b9ZtZ/VIfb2B2AIrUT/om+VDjp98Huvs7du929u0vT29gdgCK1E/49khaNe3yepL3ttQOgKu2Ef6ukpWZ2gZlNk/RBSRuLaQtA2Voe6nP3ETO7RdL3NTbUt97df1pYZwBK1dY4v7s/KenJgnoBUCFO7wWCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IKhKL92N1gx8/opkfXTGSRdQet28S15NPrfvskda6um4C3/44WR91nNn5tbm/8t/tLVvtIcjPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTh/Bxj+ztJkfceKfy1t30fzTxFoys+u/kayfl/3gtzaQ5v+LPnc0Z27WuoJzeHIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBtTXOb2YDkg5JGpU04u7dRTR1umk0jv+TFQ+Wtu9/+/WSZP2uvmuT9cXnp68H8NTyR5P1v541mFu7/ea5yecu+TTj/GUq4iSfq919fwHbAVAh3vYDQbUbfpf0lJltM7PeIhoCUI123/Zf6e57zexcSZvM7Gfu/vT4FbI/Cr2SNENvaHN3AIrS1pHf3fdmt0OSHpO0coJ11rl7t7t3d2l6O7sDUKCWw29mM81s1vH7kt4jaUdRjQEoVztv++dLeszMjm/nfnf/XiFdAShdy+F395clXVZgL5PWyDVvS9Z/eNlXG2yhK1n98vCyZP1Hf5U4vWLvUPK5y4b7k/UpM2Yk61/Y8ifJ+tq523NrI7NHks9FuRjqA4Ii/EBQhB8IivADQRF+ICjCDwTFpbsL8NrCacn6lAZ/YxsN5f34/enhtNGXf56st2P3Zy9P1u+fc2eDLeSf1Xne9zj21IlXHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYpy/AOfc25es/2X/3yTrNnwwWR8ZHDjFjorz0et/kKyfNYWrM01WHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjG+Ssw+tIv6m4h18DtVyTrHznnSw22kL6095rBd+TWZv1gZ/K5ow32jPZw5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBqO85vZeknvkzTk7pdmy+ZI+pakxZIGJN3k7sPltYlW/fpD6XH8n/xtehz/7Cnpcfy+w1OT9Rc+n3/d/zMPPpd8LsrVzJH/m5KuO2HZrZI2u/tSSZuzxwAmkYbhd/enJR04YfEqSRuy+xsk3VBwXwBK1upn/vnuPihJ2e25xbUEoAqln9tvZr2SeiVpht5Q9u4ANKnVI/8+M1sgSdntUN6K7r7O3bvdvbsrMWkjgGq1Gv6Nknqy+z2SniimHQBVaRh+M3tAUp+kPzazPWb2EUl3SLrWzHZJujZ7DGASafiZ391X55SuKbgXlGD/Wz1ZbzSO30jPjz+arC97nLH8TsUZfkBQhB8IivADQRF+ICjCDwRF+IGguHT3aeDIpvNza30X3dng2emhvsv6epL1i9f8d7LO5bc7F0d+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf5J4Iwli5P1z73l33Nrsxv8ZHfb4fS+z/9ceqR+dJgrtk9WHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjG+SeBCx/6VbJ++bTW/4av3vz3yfqy/9ra8rbR2TjyA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQDcf5zWy9pPdJGnL3S7Nlt0n6O0mvZqutdfcny2rydDfcc0Wy/tn5ja69Pz230jPw58lnXvyp3ck6190/fTVz5P+mpOsmWH63u6/I/hF8YJJpGH53f1rSgQp6AVChdj7z32JmL5rZejObXVhHACrRavi/JulCSSskDUrK/VBqZr1m1m9m/UfV4IJxACrTUvjdfZ+7j7r7MUlfl7Qyse46d+929+6uxBdTAKrVUvjNbMG4hx+QtKOYdgBUpZmhvgckXSVprpntkfQZSVeZ2QpJLmlA0sdK7BFACRqG391XT7D4nhJ6OW2dsfCPkvV3/9OWZP2sKa1/XOp76S3J+rJhfq8fFWf4AUERfiAowg8ERfiBoAg/EBThB4Li0t0V2Ll2UbL++Ju+3db2r95+Y26Nn+wiD0d+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf4KbHv/3Q3WaO8KR2f/w7Hc2sjwcFvbxumLIz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4/2ng6Pyzc2tdRxZW2MnJRl/dn1vzw+np22x6+vyHqfPmttSTJI3OOydZ37VmWsvbboaPWm7ton9scA2GgwcL6YEjPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E1XCc38wWSbpX0pskHZO0zt2/YmZzJH1L0mJJA5Jucnd+PF6D7zy8vu4Wcr3zPyea4X3M/n1vTD539rxDyfqWt93fUk+dbvk/35KsL/lUXyH7aebIPyJpjbtfLOkdkj5uZssl3Spps7svlbQ5ewxgkmgYfncfdPfns/uHJO2UtFDSKkkbstU2SLqhrCYBFO+UPvOb2WJJl0vaImm+uw9KY38gJJ1bdHMAytN0+M3sLEmPSPqkuzd9crGZ9ZpZv5n1H1X6XG4A1Wkq/GbWpbHg3+fuj2aL95nZgqy+QNLQRM9193Xu3u3u3V1tXqgSQHEaht/MTNI9kna6+13jShsl9WT3eyQ9UXx7AMpi7p5ewexdkp6RtF1jQ32StFZjn/sfkvRmSa9IutHdD6S29Uab42+3a9rtedL5v+9fkKxvvvThijqJ5Xd+JLd21PMvd96M61+8OVn/zQut/9x4wbMjyfr0727NrW3xzTroB/J/LzxOw3F+d39WUt7G4iUZOE1whh8QFOEHgiL8QFCEHwiK8ANBEX4gKC7dXYEz/+J/kvVLvpD+CaeX+F9p1kXJUzNK/dnsJc98OFn3V2a2tf0lD7+WX3xue1vbnq1dbdU7AUd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiq4e/5ixT19/xAVU7l9/wc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCohuE3s0Vm9iMz22lmPzWzT2TLbzOzX5nZC9m/68tvF0BRmpkOYkTSGnd/3sxmSdpmZpuy2t3u/qXy2gNQlobhd/dBSYPZ/UNmtlPSwrIbA1CuU/rMb2aLJV0uaUu26BYze9HM1pvZ7Jzn9JpZv5n1H9XhtpoFUJymw29mZ0l6RNIn3f2gpK9JulDSCo29M7hzoue5+zp373b37i5NL6BlAEVoKvxm1qWx4N/n7o9Kkrvvc/dRdz8m6euSVpbXJoCiNfNtv0m6R9JOd79r3PIF41b7gKQdxbcHoCzNfNt/paQPSdpuZi9ky9ZKWm1mKyS5pAFJHyulQwClaObb/mclTXQd8CeLbwdAVTjDDwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EJS5e3U7M3tV0v+OWzRX0v7KGjg1ndpbp/Yl0VuriuztfHef18yKlYb/pJ2b9bt7d20NJHRqb53al0RvraqrN972A0ERfiCousO/rub9p3Rqb53al0Rvraqlt1o/8wOoT91HfgA1qSX8Znadmf3czHab2a119JDHzAbMbHs283B/zb2sN7MhM9sxbtkcM9tkZruy2wmnSaupt46YuTkxs3Str12nzXhd+dt+M5sq6ReSrpW0R9JWSavd/aVKG8lhZgOSut299jFhM/tTSa9JutfdL82WfVHSAXe/I/vDOdvdP90hvd0m6bW6Z27OJpRZMH5maUk3SLpZNb52ib5uUg2vWx1H/pWSdrv7y+5+RNKDklbV0EfHc/enJR04YfEqSRuy+xs09j9P5XJ66wjuPujuz2f3D0k6PrN0ra9doq9a1BH+hZJ+Oe7xHnXWlN8u6Skz22ZmvXU3M4H52bTpx6dPP7fmfk7UcObmKp0ws3THvHatzHhdtDrCP9HsP5005HClu79V0nslfTx7e4vmNDVzc1UmmFm6I7Q643XR6gj/HkmLxj0+T9LeGvqYkLvvzW6HJD2mzpt9eN/xSVKz26Ga+3ldJ83cPNHM0uqA166TZryuI/xbJS01swvMbJqkD0raWEMfJzGzmdkXMTKzmZLeo86bfXijpJ7sfo+kJ2rs5Q90yszNeTNLq+bXrtNmvK7lJJ9sKOPLkqZKWu/ut1fexATMbInGjvbS2CSm99fZm5k9IOkqjf3qa5+kz0h6XNJDkt4s6RVJN7p75V+85fR2lcbeur4+c/Pxz9gV9/YuSc9I2i7pWLZ4rcY+X9f22iX6Wq0aXjfO8AOC4gw/ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANB/R5UEeYO44sn+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = 10000\n",
    "batch_size = 32\n",
    "\n",
    "test_img = x_test[1]\n",
    "plt.imshow(test_img)\n",
    "test_img = test_img.reshape(-1, 28, 28, 1)\n",
    "\n",
    "x_train = x_train.reshape(-1, image_height, image_width, 1)\n",
    "\n",
    "cnn = CNN(28, 28, 1, 10)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    step = 0\n",
    "    while step < steps:\n",
    "        none, currentAcurracy = sess.run((cnn.train_operation, cnn.accuracy_op), feed_dict = {cnn.input_layer:x_train[step:step+batch_size], cnn.labels:y_train[step:step+batch_size]})\n",
    "        step += batch_size\n",
    "        \n",
    "        if steps % 100 == 0:\n",
    "            print(currentAcurracy)\n",
    "    \n",
    "    print(\"\\nIt is done.\")\n",
    "    \n",
    "    #prints the number the computer thinks  is correct\n",
    "    print(\"\\n\" + str(sess.run(cnn.choice, feed_dict = {cnn.input_layer:test_img})))\n",
    "    \n",
    "#Multiply steps and batch size, and then if the number is bigger than the total number of images,\n",
    "#then drop the step value. MNIST has 60000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-6-06143a556f89>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-06143a556f89>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    print(\"The computer thinks that image is \" + str(sess.run(cnn.choice, feed_dict = {cnn.input_layer:test_img}))\u001b[0m\n\u001b[0m                                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#Testing and revising the CNN\n",
    "\n",
    "test_img = x_test[1]\n",
    "plt.imshow(test_img)\n",
    "plt.show()\n",
    "\n",
    "test_img = test_img.reshape(-1, 28, 28, 1)\n",
    "\n",
    "x_train = x_train.reshape(-1, image_height, image_width, 1)\n",
    "cnn = CNN(28, 28, 1, 10)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    step = 0\n",
    "    while step < steps:\n",
    "        sess.run((cnn.train_operation, cnn.accuracy_op), feed_dict = {cnn.input_layer:x_train[step:step+batch_size], cnn.labels:y_train[step:step+batch_size]})\n",
    "        step += batch_size\n",
    "    \n",
    "    print(\"The computer thinks that image is \" + str(sess.run(cnn.choice, feed_dict = {cnn.input_layer:test_img}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
